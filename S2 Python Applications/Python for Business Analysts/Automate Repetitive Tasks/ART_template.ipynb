{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Python for Business Analysts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Automate Repetitive Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this mission, we will explore how we can use Python to automate tasks for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 2 variables, housing_2007 and housing_2005, that contain the DataFrame objects associated with Hud_2007.csv and Hud_2005.csv, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "housing_2007 = pandas.read_csv(\"data/Hud_2007.csv\")\n",
    "housing_2005 = pandas.read_csv(\"data/Hud_2005.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2: Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have read in both datasets into DataFrame objects, let's add them to a List. A List is type of object (just like a DataFrame, Integer, or String) that contains an ordered group of objects. Just like how a grocery list contains a group of \"ingredient\" objects to buy, is a List object in Python houses a group of the objects we add to it. Instead of writing code to manipulate each object separately (in our case the objects are DataFrames), we can group a few objects into a List object, write the logic once, and apply it to every object in that List. This saves us a lot of time and energy, and will be important when we deal with much larger datasets with tens, hundreds or even thousands of DataFrames.\n",
    "\n",
    "In the following code block, we will create an empty List called data_frames_list by assigning it empty brackets: []\n",
    "\n",
    "Then, we will add a year column for each DataFrame to keep track of which DataFrame is which:\n",
    "\n",
    "housing_2005['year'] = '2005'\n",
    "housing_2007['year'] = '2007'\n",
    "\n",
    "Each row now has a value for year, either 2005 or 2007, identifying which dataset that row originated from. Finally, we will use .append() to first add housing_2005 then housing_2007 to the end of data_frames_list. The List object preserves the order by which the DataFrames were added:\n",
    "\n",
    "data_frames_list.append(housing_2005)\n",
    "data_frames_list.append(housing_2007)\n",
    "\n",
    "The list now contains these two DataFrames in the order we added them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Create list.\n",
    "data_frames_list = []\n",
    "\n",
    "# Add a year column to each dataframe.\n",
    "housing_2005['year'] = '2005'\n",
    "housing_2007['year'] = '2007'\n",
    "\n",
    "# .append() adds the specified object to the end of the list.\n",
    "data_frames_list.append(housing_2005)\n",
    "data_frames_list.append(housing_2007)\n",
    "\n",
    "# List now contains 2 objects, the respective dataframes for 2005 and 2007.\n",
    "print len(data_frames_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3: Column Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After appending both DataFrames, we ran print() on len(data_frames_list) to display the number of elements, or length, of the list to verify that we added two DataFrame objects to the list.\n",
    "\n",
    "Let's now practice Pandas' column filtering feature that we learned in the previous lesson. Create a new DataFrame, filtered_housing_2007, that contains the column filtered version of housing_2007, with just the columns we are interested in. The columns we want are: ['AGE1', 'FMR', 'TOTSAL', 'year']."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a List variable, columns, that contains the names of all of the columns we are interested in. When specifying the elements we want in the list, we need to surround each column name we want with quotes (either single or double quotes), add a comma between each column name, and then surround the whole thing with a starting [ and closing bracket ]. Then, we use bracket notation on the DataFrame object to specify a filter. We want the filter to just contain the columns list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AGE1   FMR  TOTSAL  year\n",
      "0    -9  1048      -9  2007\n",
      "1    69  1048       0  2007\n",
      "2    45   757   26000  2007\n",
      "3    47   847  126000  2007\n",
      "4    30   616   42000  2007\n"
     ]
    }
   ],
   "source": [
    "columns = []\n",
    "filtered_housing_2007 = []\n",
    "\n",
    "# Create list of column names to filter by.\n",
    "columns = ['AGE1', 'FMR', 'TOTSAL', 'year']\n",
    "\n",
    "# Filter dataframe.\n",
    "filtered_housing_2007 = housing_2007[columns]\n",
    "\n",
    "print filtered_housing_2007[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###4: Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will learn how to write our own functions. Functions are core to every programming language and are a powerful way to package logic and apply it wherever we see fit. They can take an object as an input, apply pre-written logic on the input, and then return a modified object. Functions are like factories that take in raw materials, add other materials and processes to them, and then crank out finished products. In the next code block, we define a function filter_columns, that takes in an input, data_frames_list, and returns a new list new_df_list.\n",
    "\n",
    "We want the function to filter each DataFrame down to only the columns we want. Let's use the same columns from the last code block: * 'AGE1', 'FMR', 'TOTSAL', year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_columns(data_frames_list):\n",
    "    # Create list.\n",
    "    new_df_list = list()\n",
    "    \n",
    "    # Look through each dataframe.\n",
    "    for df in data_frames_list:\n",
    "        # Create list of column names to filter by.\n",
    "        columns = ['AGE1', 'FMR', 'TOTSAL', 'year']\n",
    "        # Filter dataframe.\n",
    "        filtered_df = df[columns]\n",
    "        # Append filtered dataframe to 'new_df_list'.\n",
    "        new_df_list.append(filtered_df)\n",
    "\n",
    "    return new_df_list\n",
    "\n",
    "filtered_data_frames_list = filter_columns(data_frames_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###5: Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's walk through what we wrote, step by step.\n",
    "\n",
    "In the function above, we used a for loop:\n",
    "\n",
    "for df in data_frames_list:\n",
    "\n",
    "to iterate over all of the object in data_frames_list (which contained our twp DataFrames we added earlier) and applied our column filtering logic. We iterated over a list object by object, referring to the current object we were applying the logic to as df.\n",
    "\n",
    "Instead of hard coding the columns we want at the filter level like we did in the last lesson:\n",
    "\n",
    "filtered_housing_2013 = housing_2013[[ 'AGE1', 'FMR',  'TOTSAL', 'year' ]]\n",
    "\n",
    "we assigned the column names to a list object, called columns:\n",
    "\n",
    "columns = ['AGE1', 'FMR', 'TOTSAL', 'year']\n",
    "\n",
    "and passed it into the filter criteria:\n",
    "\n",
    "filtered_df = df[columns]\n",
    "\n",
    "Instead of creating two different DataFrame objects (like filtered_housing_2005, filtered_housing_2007, etc), we created an empty list called new_df_list:\n",
    "\n",
    "new_df_list = list()\n",
    "\n",
    "and appended each of the filtered_df objects to it:\n",
    "\n",
    "new_df_list.append(filtered_df)\n",
    "\n",
    "As you can see, we placed a heavy emphasis on abstracting, or generalizing, our logic so we can detail the logic once, and apply it in many cases. The filter_columns function that we wrote is essentially a piece of software that will filter any list of DataFrame objects into the 4 columns we want. Whether the list of DataFrame objects has 1 DataFrame object or 25, the same function can be applied to get the result we want. Another abstraction we could implement would be to modify the function and specify the columns we want filtered every time by adding it as an input to the function (alongside data_frames_list). This way, instead of always using a specific set of columns within the function, the user can now specify in the input which columns they prefer to filter their DataFrames.\n",
    "\n",
    "This is the power of abstraction. It allows us to automate repetitive work incredibly easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###6: Column Filtering Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly verify that each of the DataFrame objects in filtered_data_frames_list only contains the 4 columns we specified in columns. Here we will write a print() statement within a for loop to print all of the columns in each DataFrame housed in filtered_data_frames_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'AGE1', u'FMR', u'TOTSAL', u'year'], dtype='object')\n",
      "Index([u'AGE1', u'FMR', u'TOTSAL', u'year'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# For every dataframe in the list 'filtered_data_frames_list'.\n",
    "for df in filtered_data_frames_list:\n",
    "    # Print dataframe columns.\n",
    "    print df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###7: Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our column filter was applied to every DataFrame in the list, filtered_data_frames_list, and each DataFrame now contains only the 4 columns we are interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###8: Multiple Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write a function that counts the number of rows in each DataFrame that have negative values for the AGE1 column. We will also use Python's ability to custom print values.\n",
    "\n",
    "In the following code block:\n",
    "\n",
    "print( str(year) + \" - \" + str(len( negative_age_count ) ) + \" rows\")\n",
    "\n",
    "we use the function str() to convert Integer objects, like year and len(negative_age_count), into String objects. The print function can only print String objects, so we must convert other objects to String objects. While not all objects can be converted to String objects for displaying, most can and we will cover in a later lesson how we can tell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005 - 3493 rows\n",
      "2007 - 3622 rows\n"
     ]
    }
   ],
   "source": [
    "# For every dataframe in the list 'filtered_data_frames_list'.\n",
    "for df in filtered_data_frames_list:\n",
    "    # Get the dataframe year.\n",
    "    year = df['year'][0]\n",
    "    # Return rows with negative age values.\n",
    "    negative_age_count = df[df['AGE1']<0]\n",
    "    # Print row count.\n",
    "    print str(year) + \" - \" + str(len( negative_age_count ) ) + \" rows\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###9: Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we loop through filtered_data_frames_list, we print that DataFrame's year, add (using +) a \"-\", add the len(negative_age_count) , and then finally add the text \"rows\".\n",
    "\n",
    "Looks like both 2005 and 2007 have several thousand rows with negative ages. Its our job to clean this up now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###10: Multiple Dataset Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you recall from the previous mission, the 2013 dataset had 4438 rows with negative ages. The 2005 and 2007 datasets are not as bad, but now we have to clean up two years’ data at the same time. Let's write a function that automates the clean up we did in the last mission so that we are left only with the rows that contain positive values for the AGE1 column.\n",
    "\n",
    "Now let's write a function clean_rows() that takes a List of DataFrames and returns a List of cleaned DataFrames with just rows containing positive AGE1 values.\n",
    "\n",
    "Inside the function, we will first instantiate, or create, an empty list with no elements:\n",
    "\n",
    "cleaned_list = list()\n",
    "\n",
    "Then, we will iterate through each DataFrame in filtered_data_frames_list, create a temporary DataFrame cleaned_df containing just the positive AGE1 rows for each DataFrame:\n",
    "\n",
    "cleaned_df = df[ df ['AGE1'] > 0 ]\n",
    "\n",
    "And then we will append cleaned_df to cleaned_list for each iteration:\n",
    "\n",
    "cleaned_list.append(cleaned_df)\n",
    "\n",
    "Let's run this function clean_rows on data_frames_list and assign the results to cleaned_data_frames_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[       AGE1   FMR  TOTSAL  year\n",
      "0        43   680   20000  2005\n",
      "1        44   760   71000  2005\n",
      "2        58   680   63000  2005\n",
      "3        22   519   27040  2005\n",
      "4        48   600   14000  2005\n",
      "5        42   788   42000  2005\n",
      "7        23   546   48000  2005\n",
      "8        51   680   58000  2005\n",
      "9        47  1081  125000  2005\n",
      "10       66  1081       0  2005\n",
      "11       47  1006   54400  2005\n",
      "12       30   874  439364  2005\n",
      "13       49   916   75000  2005\n",
      "14       60   972       0  2005\n",
      "15       47   862   80000  2005\n",
      "16       59   629     550  2005\n",
      "17       45   862   42000  2005\n",
      "18       54   607   65000  2005\n",
      "19       35   892   57000  2005\n",
      "21       33   972   58000  2005\n",
      "22       42   760   59050  2005\n",
      "23       37   963   44000  2005\n",
      "24       52   879  136000  2005\n",
      "26       27   750   42500  2005\n",
      "27       54  1035    5000  2005\n",
      "28       37   833    2000  2005\n",
      "29       52   940   77883  2005\n",
      "30       70  1080       0  2005\n",
      "31       82  1017       0  2005\n",
      "32       46  1168   14000  2005\n",
      "...     ...   ...     ...   ...\n",
      "46821    27   677   62000  2005\n",
      "46822    53   972       0  2005\n",
      "46823    42  1267   95000  2005\n",
      "46824    47  1190   53200  2005\n",
      "46825    28  1397   91000  2005\n",
      "46826    23   677   30000  2005\n",
      "46828    84   817       0  2005\n",
      "46829    36  1168   79919  2005\n",
      "46830    30  1607   82000  2005\n",
      "46831    54  1094   54000  2005\n",
      "46832    46  1190   79000  2005\n",
      "46833    46  1168   48000  2005\n",
      "46834    58   817   42500  2005\n",
      "46835    62  1168  124000  2005\n",
      "46836    56  1420   82000  2005\n",
      "46837    34  1420  103000  2005\n",
      "46838    41  1168   52000  2005\n",
      "46839    56  1607   85000  2005\n",
      "46840    30   825   24000  2005\n",
      "46841    60   825  100000  2005\n",
      "46842    46   693   46500  2005\n",
      "46843    28   825   50000  2005\n",
      "46844    26  1397   61000  2005\n",
      "46845    23  1190   57000  2005\n",
      "46846    34  1633  200000  2005\n",
      "46847    46  1168  302000  2005\n",
      "46848    33  1168  105000  2005\n",
      "46849    40  1397   65000  2005\n",
      "46850    44  1397  280400  2005\n",
      "46852    44  1420   75000  2005\n",
      "\n",
      "[43360 rows x 4 columns],        AGE1   FMR  TOTSAL  year\n",
      "1        69  1048       0  2007\n",
      "2        45   757   26000  2007\n",
      "3        47   847  126000  2007\n",
      "4        30   616   42000  2007\n",
      "5        50   605   15000  2007\n",
      "6        44   807  145000  2007\n",
      "8        24   599   96000  2007\n",
      "9        53   757   85000  2007\n",
      "10       49   974  165000  2007\n",
      "11       44   974   71000  2007\n",
      "12       61   956  104000  2007\n",
      "13       29   572       0  2007\n",
      "14       21   572   25000  2007\n",
      "15       49  1097   93000  2007\n",
      "16       31   871  485968  2007\n",
      "17       51   900   53500  2007\n",
      "18       49   930   90000  2007\n",
      "19       61   930       0  2007\n",
      "20       45   930       0  2007\n",
      "21       53   923  150000  2007\n",
      "22       56   818  125000  2007\n",
      "23       20   583   12000  2007\n",
      "24       48  1169  200000  2007\n",
      "25       34  1042   81000  2007\n",
      "26       44   847   70000  2007\n",
      "27       39   961   55000  2007\n",
      "28       54   882  130000  2007\n",
      "29       46   948  150000  2007\n",
      "30       50   951   50000  2007\n",
      "32       24   700   55000  2007\n",
      "...     ...   ...     ...   ...\n",
      "42696    71  1010       0  2007\n",
      "42697    19   896     100  2007\n",
      "42698    36  1278   96000  2007\n",
      "42700    47  1097   80400  2007\n",
      "42701    44  1147  116000  2007\n",
      "42702    65   896   90000  2007\n",
      "42703    45  1784   80000  2007\n",
      "42704    33  1359  176000  2007\n",
      "42705    50   648   44000  2007\n",
      "42706    55  1042       0  2007\n",
      "42707    49  1139   48000  2007\n",
      "42708    21   648   10000  2007\n",
      "42710    38  1278   32000  2007\n",
      "42711    34  1470  100002  2007\n",
      "42712    44  1169  162000  2007\n",
      "42713    48  1139   25000  2007\n",
      "42714    48  1278   74100  2007\n",
      "42715    65  1278   87000  2007\n",
      "42716    58  1359  120000  2007\n",
      "42717    67   963       0  2007\n",
      "42718    58  1517       0  2007\n",
      "42719    65  1517       0  2007\n",
      "42721    35  1517   12000  2007\n",
      "42722    24  1359   60000  2007\n",
      "42723    48  1278  310000  2007\n",
      "42724    57  1278   40800  2007\n",
      "42725    42  1517   94000  2007\n",
      "42726    46  1517  185000  2007\n",
      "42727    25   782       0  2007\n",
      "42728    45  1310   90000  2007\n",
      "\n",
      "[39107 rows x 4 columns]]\n"
     ]
    }
   ],
   "source": [
    "def clean_rows(filtered_data_frames_list):\n",
    "    # Create list.\n",
    "    cleaned_list = list()\n",
    "    \n",
    "    # For every dataframe in the list 'filtered_data_frames_list'.\n",
    "    for df in filtered_data_frames_list:\n",
    "        # Return rows with positive age values.\n",
    "        cleaned_df = df[df['AGE1']>0] \n",
    "        # Append filtered dataframe to 'cleaned_list'.\n",
    "        cleaned_list.append(cleaned_df)\n",
    "    return cleaned_list\n",
    "\n",
    "cleaned_data_frames_list = clean_rows(filtered_data_frames_list)\n",
    "\n",
    "print cleaned_data_frames_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###11: Verify Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a quick function to verify that cleaned_data_frames_list doesn't contain any DataFrame objects that have negative values for the AGE1 column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function verify_cleanup on cleaned_data_frames_list and assign the result to a new variable, verification_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def verify_cleanup(data_frames_list):\n",
    "    # Create count.\n",
    "    negative_rows_count = 0\n",
    "    \n",
    "    # For every dataframe in the list 'data_frames_list'.\n",
    "    for df in data_frames_list:\n",
    "        # Add the number of negative rows to 'negative_rows_count'.\n",
    "        negative_rows_count += len(df[df['AGE1']<0])\n",
    "    return negative_rows_count\n",
    "\n",
    "verification_count = -1\n",
    "verification_count = verify_cleanup(cleaned_data_frames_list)\n",
    "\n",
    "print verification_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###12: Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are zero 0 rows in all of the DataFrame objects in data_frames_list with negative values for the AGE1 column. Just like with the filter_columns function that we wrote before, clean_rows can now be applied to any future HUD datasets that we want without having to rewrite all of the logic we just wrote."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###13: Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this mission, you learned the power of automation by using lists, functions, filters and for loops. The process of writing code once that you can then apply in many situations is an underlying concept and principle in programming called Don’t Repeat Yourself, or DRY. By writing abstracted, or generalized, code that is versatile, you not only save yourself precious time, but ensure that your programs run efficiently and without bugs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
